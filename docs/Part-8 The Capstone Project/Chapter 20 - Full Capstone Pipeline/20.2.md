# 20.2: Planning via LLM

## Translating Intent into Action Sequences

Once the human's voice command is converted into text, the next critical stage in the capstone pipeline is task planning. Here, a Large Language Model (LLM) is leveraged to interpret the high-level natural language request and break it down into a sequence of actionable steps for the robot.

## Component: LLM-based Task Planner

Building upon the concepts introduced in Chapter 14, the LLM acts as a high-level cognitive agent:

*   **Input:** The textual command from the speech recognition module (e.g., "Go to the kitchen and get me a glass of water from the fridge").
*   **Process:** The LLM, pre-trained on vast text corpora and potentially fine-tuned with robotic task-specific examples, analyzes the command. It accesses its internal knowledge base (which may include robot capabilities and environmental semantics) to infer the user's intent and generate a logical, step-by-step plan.
    *   It might identify sub-goals: `GO_TO(kitchen)`, `OPEN(fridge)`, `GRASP(glass_of_water)`, `CLOSE(fridge)`, `GO_TO(user_location)`.
    *   The LLM can also engage in clarification dialogue if the initial command is ambiguous (e.g., "Which glass would you like?").
*   **Output:** A structured, abstract plan represented as a sequence of high-level actions, which are still symbolic but closer to robot capabilities. This plan might be a list of function calls or a sequence of behaviors for downstream modules.

## Key Considerations

*   **Context Provision:** The LLM's performance is greatly enhanced by providing it with contextual information, such as the robot's current location, known objects in the environment, and its available skills.
*   **Action Grounding:** The abstract actions generated by the LLM (e.g., `GRASP(glass_of_water)`) need to be grounded into the robot's perception system to identify the actual `glass_of_water` in the physical environment.
*   **Hierarchical Planning:** The LLM typically handles the high-level "what to do," leaving the "how to do it" to more specialized lower-level planners (e.g., motion planners, navigation planners).

The LLM's plan provides the overarching strategy for the autonomous humanoid, guiding its subsequent perception, navigation, and manipulation modules.
