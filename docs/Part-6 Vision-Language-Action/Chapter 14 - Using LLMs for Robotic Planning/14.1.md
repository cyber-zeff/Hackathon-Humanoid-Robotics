# 14.1: How LLMs Plan Tasks

## The Paradigm Shift in Robotic Planning

Traditionally, robotic planning involved explicit programming of every step, or using classical AI planning techniques that required detailed domain knowledge and handcrafted rules. The emergence of Large Language Models (LLMs) offers a new, more intuitive approach to robotic task planning, leveraging their vast knowledge of human language and real-world concepts.

## LLMs as Task Planners

LLMs, such as GPT-3 or Gemini, are trained on massive amounts of text data, allowing them to understand and generate human-like text. When applied to robotics, this capability can be leveraged for planning in several ways:

1.  **High-Level Task Understanding:** An LLM can take a natural language instruction (e.g., "Make me coffee") and break it down into a sequence of high-level sub-goals (e.g., "Get mug," "Brew coffee," "Add milk," "Serve").
2.  **Generating Action Sequences:** Based on its understanding of the world and robot capabilities (often provided as context), the LLM can generate a sequence of abstract actions that, if executed, would achieve the desired goal. These actions are still symbolic and need to be translated into robot-executable commands.
3.  **Handling Ambiguity and Novelty:** Unlike classical planners that struggle with novel situations, LLMs can infer plausible actions for commands they haven't seen before, thanks to their generalization capabilities. They can also ask clarifying questions when instructions are ambiguous.
4.  **Reasoning and Common Sense:** LLMs possess a degree of common-sense reasoning derived from their training data. This allows them to make more human-like decisions in planning, such as understanding that pouring coffee before getting a mug is illogical.

## Prompt Engineering for Planning

The effectiveness of using LLMs for robotic planning heavily relies on **prompt engineering**. This involves crafting the input prompt to the LLM in a way that guides it to generate a useful plan. A good prompt might include:

*   The robot's capabilities (available actions).
*   The current state of the environment.
*   The user's high-level goal.
*   Examples of desired plan formats.

By providing the right context and constraints, LLMs can transform vague human instructions into structured, actionable plans for robots.
